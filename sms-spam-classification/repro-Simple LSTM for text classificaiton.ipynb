{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repro from:\n",
    "\n",
    "https://www.kaggle.com/kredy10/simple-lstm-for-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the libraries:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['v1','v2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'no:of spam vs non spam msgs')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['v1'])\n",
    "plt.xlabel('Spam vs Ham Label')\n",
    "plt.title('no:of spam vs non spam msgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: v1, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['v1'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a class imbalance of 86.5-13.5% split between negative and positive labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.v2\n",
    "y=df.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(x,Y,test_size=0.15, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the data\n",
    "* Tokenize the data and convert the text to sequences.\n",
    "* Add padding to ensure that all the sequences have the same shape.\n",
    "* There are many ways of taking the max_len and here an arbitrary length of 150 is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 131,   1, 523,   3,  15, 172, 123,  72,  11, 124,  61,  18,\n",
       "         5, 548,   1,  59, 293,   4, 263], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_matrix[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " sequences_matrix is doing zero padding with actual words at end (of len 150) and zeros before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "Define the RNN structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs', shape=[max_len]) ## Input layer from Keras. shape is the input shape that we defined above, which is max_len(=150)\n",
    "    layer = Embedding(max_words, 50, input_length = max_len)(inputs) ## This can be used only as first layer after input layer. This converts integer indices in input layer to dense repr.\n",
    "    ## It is not needed in case we use dense word embeddings instead. input_dim = max_words, which is equivalent to vocab size. input_len is equivalent to sentence len\n",
    "    layer = LSTM(64)(layer) ## 64 units in output\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer= Dropout(0.5)(layer)\n",
    "    layer = Dense(1, name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs, outputs=layer)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of no:of params:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "\n",
    "=================================================================\n",
    "inputs (InputLayer)          (None, 150)               0         \n",
    "_________________________________________________________________\n",
    "embedding_1 (Embedding)      (None, 150, 50)           50000     \n",
    "\n",
    "How: input max words = 1000 is input dimension. Output is 50. 1000* 50 = 50000\n",
    "_________________________________________________________________\n",
    "lstm_1 (LSTM)                (None, 64)                29440     \n",
    "\n",
    "How: Input, hidden ,output, state = 4 cells. Each cell contains output (64) no : of units.\n",
    "\n",
    "Input contains input word len + prev output (LSTM output)  = 50 + 64 + Bias =1\n",
    "\n",
    "Output contains 64 \n",
    "\n",
    "Params = 4 * (50 + 64 + 1) * 64 = 29440\n",
    "\n",
    "\n",
    "_________________________________________________________________\n",
    "FC1 (Dense)                  (None, 256)               16640     \n",
    "\n",
    "How: LSTM output = 64 + bias= 1\n",
    "Dense output = 256\n",
    "Params = 65 * 256 = 16640\n",
    "\n",
    "_________________________________________________________________\n",
    "activation_1 (Activation)    (None, 256)               0         \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 256)               0         \n",
    "_________________________________________________________________\n",
    "out_layer (Dense)            (None, 1)                 257       \n",
    "Params = input from prev layer = 256 + bias = 257\n",
    "_________________________________________________________________\n",
    "\n",
    "activation_2 (Activation)    (None, 1)                 0         \n",
    "\n",
    "============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3788 samples, validate on 948 samples\n",
      "Epoch 1/10\n",
      "3788/3788 [==============================] - 5s 1ms/step - loss: 0.3411 - acc: 0.8714 - val_loss: 0.1244 - val_acc: 0.9757\n",
      "Epoch 2/10\n",
      "3788/3788 [==============================] - 5s 1ms/step - loss: 0.0956 - acc: 0.9773 - val_loss: 0.0541 - val_acc: 0.9852\n",
      "Epoch 3/10\n",
      "3788/3788 [==============================] - 5s 1ms/step - loss: 0.0520 - acc: 0.9863 - val_loss: 0.0531 - val_acc: 0.9842\n",
      "Epoch 4/10\n",
      "3788/3788 [==============================] - 5s 1ms/step - loss: 0.0419 - acc: 0.9852 - val_loss: 0.0596 - val_acc: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1100e6f28>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within 4 epochs, the val_loss stopped improving and instead started to deteriorate (increased from 0.0531 to 0.0596) because of EarlyStopping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequences_test = tok.texts_to_sequences(X_test)\n",
    "sequences_matrix_test = sequence.pad_sequences(sequences_test,maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 1s 612us/step\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(sequences_matrix_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 0.074\n",
      "  Accuracy: 0.971\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen earlier, we had 86.5% negative and 13.5 positive classes. The model has an accuracy of 97%, which is more than 10 percent points from random prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
